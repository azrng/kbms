<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.19" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.66" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://azrng.gitee.io/kbms/kbms/ai/localMode.html"><meta property="og:site_name" content="知识库"><meta property="og:title" content="本地大模型初体验"><meta property="og:description" content="Ollama Ollama是一款开源的大模型管理工具，它允许用户在本地便捷地运行多种大型开源模型，包括清华大学的ChatGLM、阿里的千问以及Meta的llama等。目前，Ollama兼容macOS、Linux和Windows三大主流操作系统。 官网：https://ollama.com/ 命令行 部署 这里我们直接使用docker部署的Ollama，..."><meta property="og:type" content="website"><meta property="og:image" content="https://azrng.gitee.io/kbms/kbms/ai/1350373-20250101211657228-597289635.png"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-01-04T14:20:36.000Z"><meta property="article:author" content="azrng"><meta property="article:tag" content="大模型"><meta property="article:published_time" content="2025-01-01T00:00:00.000Z"><meta property="article:modified_time" content="2025-01-04T14:20:36.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebPage","name":"本地大模型初体验","description":"Ollama Ollama是一款开源的大模型管理工具，它允许用户在本地便捷地运行多种大型开源模型，包括清华大学的ChatGLM、阿里的千问以及Meta的llama等。目前，Ollama兼容macOS、Linux和Windows三大主流操作系统。 官网：https://ollama.com/ 命令行 部署 这里我们直接使用docker部署的Ollama，..."}</script><script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?1f046e495f9c28ef302f30895bda829e";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script><title>本地大模型初体验 | 知识库</title><meta name="description" content="Ollama Ollama是一款开源的大模型管理工具，它允许用户在本地便捷地运行多种大型开源模型，包括清华大学的ChatGLM、阿里的千问以及Meta的llama等。目前，Ollama兼容macOS、Linux和Windows三大主流操作系统。 官网：https://ollama.com/ 命令行 部署 这里我们直接使用docker部署的Ollama，...">
    <link rel="preload" href="/kbms/assets/style-DicSTiUB.css" as="style"><link rel="stylesheet" href="/kbms/assets/style-DicSTiUB.css">
    <link rel="modulepreload" href="/kbms/assets/app-BQsqMNmR.js"><link rel="modulepreload" href="/kbms/assets/localMode.html-DLEbg4KS.js"><link rel="modulepreload" href="/kbms/assets/plugin-vue_export-helper-DlAUqK2U.js">
    
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!----><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/kbms/assets/app-BQsqMNmR.js" defer></script>
  </body>
</html>
